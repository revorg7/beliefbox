## -*- Mode: Org -*-


These are benchmark results.

* Optdigits dataset

Strangely enough, the un-normalised results are much better than the
normalised ones. What gives? However, sensitivity to the metric
is to be expected for the k-nearest-neighbour methods.

** Normalised
|-----------------+------------+------------+-----------+-----------|
| Method          | Train Err. | Train Acc. | Test Err. | Test Acc. |
|-----------------+------------+------------+-----------+-----------|
| Normal-Wishart  |   0.023019 |   0.977207 |  0.050083 |  0.949042 |
| 1-NN            |   0.000000 |   1.000000 |  0.099610 |  0.900390 |
| 2-NN            |   0.038975 |   0.962987 |  0.120757 |  0.883139 |
| 3-NN            |   0.036097 |   0.941059 |  0.101836 |  0.876461 |
| Linear 0.1x10   |   0.110646 |   0.884982 |  0.146912 |  0.848606 |
| SLin 512 0.1x10 |   0.077426 |   0.922626 |  0.116861 |  0.883426 |
|                 |            |            |           |           |
|-----------------+------------+------------+-----------+-----------|


** Un-normalised
|----------------+------------+------------+-----------+-----------|
| Method         | Train Err. | Train Acc. | Test Err. | Test Acc. |
|----------------+------------+------------+-----------+-----------|
| Normal-Wishart |    0.10986 |   0.989307 |  0.046745 |  0.953676 |
| Tree-0 N-W     |    0.10986 |   0.988418 |  0.046745 |   0.95282 |
| Tree-1 N-W     |    0.10986 |   0.988418 |  0.046745 |   0.95282 |
| 1-NN           |   0.000000 |   1.000000 |  0.020033 |  0.979967 |
| 2-NN           |   0.008370 |   0.993068 |  0.026155 |  0.975237 |
| 3-NN           |   0.007324 |   0.988665 |  0.021703 |  0.971619 |
|----------------+------------+------------+-----------+-----------|


